** Preprocessing of Very High Resolution optical imagery             :slides:
*** Goals and data
**** Goals
     - Know how to perform optical calibration
     - Know how to perform image fusion (pan-sharpening)
     - Know how to perform ortho-rectification
**** Data
     Data are available in the ~Data/preprocessing/~ directory. Sub-directories
     ~SRTM~ and ~Geoid~ are also used.
*** Outline
    The outline for this workshop is as follows:
    1. Atmospheric corrections
    2. P+XS fusion
    3. Ortho-rectification
*** Optical calibration
**** Atmospheric correction
     #+ATTR_LATEX: :float t :width 0.7\textwidth
     [[file:Images/atmo_correction.png]]
     (source http://www.hkcoastalwaterquality.tk/Methodology.html)
**** Digital numbers (DN)
     Output from the sensor (no unit, sensor dependent)
**** Luminance
     Luminance is the measure of the amount of light (W.m-2.sr-1)
**** Top Of Atmosphere (TOA) Reflectance
     The reflectance of the surface of a material is its effectiveness in
     reflecting radiant energy.
     It is the fraction of incident electromagnetic power that is reflected at an interface.
     TOA: measured at the top of the atmosphere; contains atmospheric effects.
     Percentage, no unit.
**** Top Of Canopy (TOC) Reflectance 
     Reflectance at the surface of the observed objects, after atmospheric effects correction.

*** Fusion (pan-sharpening)
    
**** What is pan-sharpening?
    - Most VHR sensors acquire 2 different images:
      - The multi-spectral bands cover a narrow range with lower spatial
        resolution (than PAN)
      - The panchromatic band with a larger spectral range and a higher
        spatial resolution (4x greater usually)
    - Pansharpening =  process of merging high-resolution panchromatic and lower resolution multispectral imagery to create a single high-resolution color image

**** PXS in a nutshell
     1. Fine registation of PAN and XS bands
     2. Fusion algorithm

*** Orthorectification

     #+BEGIN_LaTeX
     \begin{center}
     \begin{tikzpicture}[scale=0.2]
    \tiny
    \draw[fill=black!10] (-1,-12) rectangle (75,17);
     \foreach \x in {5,...,1}
       \draw[fill=red] (\x,\x) rectangle +(4,4);
     \node[fill=black!10, text width= 1.5cm] (InputSeries) at
       (4,-1) {Input series};
     %\pause
     \draw[->,thick] (9,5) --  +(3,0);
     %%\pause
     \draw[fill=black!30,rounded corners=2pt] (12.2,3) rectangle +(6,4);
     \node[text width= 0.8cm] (SensorModel) at (15,5) {Sensor Model};
     %\pause
     \draw[fill=red!30] (1,-10) rectangle +(4,4);
     \node[fill=black!10, text width= 1.2cm] (DEM) at
       (5,-11) {DEM};
     %\pause
     \draw[->,thick] (3,-5.5) --  ++(0,3) -- ++(12,0) -- ++(0,5);
     %\pause
     \draw[->,thick] (18.5,5) --  +(3,0);
     %\pause
     \foreach \x in {5,...,1}
       \draw[fill=blue,xshift=600pt] (\x,\x) rectangle +(4,4);
     \node[fill=black!10, text width= 2.8cm] (GeoRefSeries) at
       (28,-1) {Geo-referenced Series};
%\pause
      

       \draw[->,thick] (25.5,8.5) --  +(0,3);
       
     \draw[fill=black!30,rounded corners=2pt] (22,12) rectangle +(8.5,4);
     \node[text width= 1.5cm] (HomPoExtr) at (27,14) {Homologous Points};

     \draw[->,thick] (21.5,14) --  +(-2.5,0);

     \draw[fill=black!30,rounded corners=2pt] (11,12) rectangle +(8,4);
     \node[text width= 1.3cm] (BBAdj) at (15.5,14) {Bundle-block Adjustement};

     \draw[->,thick] (15,11.5) --  +(0,-4);

     %\pause
      \draw[->,thick] (30,5) --  +(3,0);
      %\pause
     \draw[fill=black!30,rounded corners=2pt] (33.2,2.5) rectangle +(6,4.5);
     \node[text width= 0.7cm] (FineRegistration) at (36,4.9) {Fine Registration};
     %\pause

     
     \draw[->,thick] (39.5,5) --  +(3,0);
     %\pause
     \foreach \x in {5,...,1}
       \draw[fill=green,xshift=1200pt] (\x,\x) rectangle +(4,4);
     \node[fill=black!10, text width= 1.8cm] (RegistSeries) at
       (47,-1) {Registered Series};
     %\pause
     \draw[->,thick] (36,2) --  ++(0,-10) -- ++(-30,0);

     %\pause
      \draw[->,thick] (52,5) --  +(3,0);
      %\pause
     \draw[fill=black!30,rounded corners=2pt] (55.2,2.5) rectangle +(6,4.5);
     \node[text width= 0.7cm] (CartoProjection) at (57.5,4.9)
          {Map Projection};
     %\pause

     
     \draw[->,thick] (61.5,5) --  +(3,0);
     %\pause
     \foreach \x in {5,...,1}
       \draw[fill=yellow,xshift=1810pt] (\x,\x) rectangle +(4,4);
     \node[fill=black!10, text width= 1.95cm] (CartoSeries) at
       (68,-1) {Cartographic Series};
     
       
     \end{tikzpicture}
     \end{center}
     #+END_LaTeX
    

** Preprocessing of Very High Resolution optical imagery                          :guide:
*** Description                                                        :desc:
**** Summary
     This exercise allows to get familiar with radiometric and geometric
     corrections using OTB applications. 

**** Prerequisites
     - Basic knowledge of remote sensing imagery
     - Basic knowledge on how to use OTB applications
       
**** Goal
***** Know how to perform optical calibration
      - Allow to compare and validate values between images and sensors (multi-temp) and multi-sensors
      - Convert DN into TOA (Top of Atmosphere) reflectance and TOC (Top of Canopy)
***** Know how to perform image fusion (pan-sharpening)
      - Pan (higher spatial resolution) and XS (higher spectral resolution)
      - Test several fusion methods
      - Special modes available for PHR Pleiades image fusion (Pléiades /mode/)
      - See effects of image fusion (moving objects, radiometric calibration)
***** Know how to perform orthorectification
      - Spatially locate satellite images
      - Associate geographical coordinates to pixel positions
      - Know prerequisites; bias, approximations
       
*** Steps                                                             :steps:

Data are located in the ~Data/preprocessing/~ folder. We will also use the ~SRTM~ and ~Geoid~ 
folders.

In this part of the exercise, you will use the ~phr_xs_osr_mipy.tif~ and
~phr_pan_osr_mipy.tif~ images. Those are extracts of PAN and XS from a Pleiades product
(Bundle Primary Level 1A) acquired over the south west of Toulouse. 

**** Atmospheric corrections
     The goal is to convert Digital Numbers into reflectances (physical values). The
process is composed of 2 steps: computation of Top Of Atmosphere reflectance and
then surface reflectance which consists in taking into account atmospheric
effects.
     #+BEGIN_LaTeX


     \begin{center}
\begin{tikzpicture}[scale=0.18]
   \tiny

    \draw[->,thick] (0,0) --  +(3,0);
%     \pause

    \draw[fill=black!30,rounded corners=2pt] (4,-2) rectangle +(6,4);
    \node[text width= 0.8cm] (SensorModel) at (7,0) {DN to Lum};
%     \pause

    \draw[->,thick] (11,0) --  +(3,0);
%     \pause

    \draw[fill=black!30,rounded corners=2pt] (16,-2) rectangle +(6,4);
    \node[text width= 0.85cm] (SensorModel) at (19,0) {Lum to Refl};
%     \pause


    \draw[->,thick] (23,0) --  +(3,0);
%     \pause

    \draw[fill=black!30,rounded corners=2pt] (27,-2) rectangle +(6,4);
    \node[text width= 0.85cm] (SensorModel) at (30,0) {TOA to TOC};
%     \pause

    \draw[->,thick] (34,0) --  +(3,0);
%     \pause

    \draw[fill=black!30,rounded corners=2pt] (38,-2) rectangle +(6.5,4);
    \node[text width= 0.85cm] (SensorModel) at (41,0) {Adjacency};
%     \pause

    \draw[->,thick] (45,0) --  +(3,0);

 \end{tikzpicture}
\end{center}

#+END_LaTeX 

With ~phr_xs_osr_mipy.tif~:

1. Use the *OpticalCalibration* application to compute TOA reflectance.
2. Use the *OpticalCalibration* application to compute surface reflectance (TOC, top of canopy).
3. Compare both images using Monteverdi or another OTB application
   (TOA-TOC). Compare the red, green and blue (B0,B1,B2) bands of the
   TOA and TOC images. Which band is more impacted by atmospheric
   effects ?
4. Apply operations 1, 2 and optionally 3 to the panchromatic image ~phr_pan_osr_mipy.tif~.

_Tips :_
- Use '-milli' option which allows to save the output image in integer (16 bits). By
  default reflectance images are saved as float values (between 0 and 1).

**** P+XS Fusion
     The goal of the exercise is to create a pan-sharpened image from
     the PAN and XS bundle. Physical constraints on sensor and
     telescope design do not allow to have at the same time high
     spatial and spectral resolutions. Indeed, the reduction of the
     sampling is accompanied by a decrease of the received signal, so
     the SNR decreases. This is compensated by increasing the diameter
     of the entrance pupil or by using specific detectors to charge
     accumulation (TDI) and also varying the width of the spectral
     band. There is also a constraint on the amount of data
     that can be archived in the satellite memory. Finally, the bandwidth of the downlink to send the image to the ground is also limited.

     As a consequence most VHR sensors deliver 2 types of images:

     - Multi-spectral (XS): separate spectral bands each on a spectral range (can
       overlap). For Pléiades, 4 bands (B,G,R,NIR) with a spatial resolution of
       2.8m (resampled to 2m).
     - Panchromatic (PAN): grey level image with a detector which covers
       a larger spectral range (for an improved SNR) which allows to acquire images at 0.7m
       in the case of Pléiades (resampled to 0.5m).
     
     We will perform pan-sharpening using TOA reflectance PAN and XS images (
     ~phr_xs_osr_mipy_toa.tif~ and ~phr_xs_osr_mipy_toa.tif~)
         
     1. Use the *BundleToPerfectSensor* application to superimpose and fuse the PAN
        and XS images. Note that the application has a /phr/ mode (Pléiades)
        which allows to perform image registration without the need of sensor
        model parameters (default mode). Indeed, the PHR mode takes advantage of
        the fact that Pléiades bundle are colocalised on the same grid.
     2. Which fusion algorithm is used in the *BundleToPerfectSensor* application?
     3. (optional) Use applications *Superimpose* and *Pansharpening* to perform
        pan-sharpening with other fusion methods available in OTB.

**** Orthorectification
     
     This operation allows to associate a ground coordinate (geographical position) to every pixel in the image.

     The schema below describes all steps that can be required to go from a set
     of Level 1 products to a coregistered and colocalized image stack. 

     #+BEGIN_LaTeX
     \begin{center}
     \begin{tikzpicture}[scale=0.2]
    \tiny
    \draw[fill=black!10] (-1,-12) rectangle (75,17);
     \foreach \x in {5,...,1}
       \draw[fill=red] (\x,\x) rectangle +(4,4);
     \node[fill=black!10, text width= 1.5cm] (InputSeries) at
       (4,-1) {Input series};
     %\pause
     \draw[->,thick] (9,5) --  +(3,0);
     %%\pause
     \draw[fill=black!30,rounded corners=2pt] (12.2,3) rectangle +(6,4);
     \node[text width= 0.8cm] (SensorModel) at (15,5) {Sensor Model};
     %\pause
     \draw[fill=red!30] (1,-10) rectangle +(4,4);
     \node[fill=black!10, text width= 1.2cm] (DEM) at
       (5,-11) {DEM};
     %\pause
     \draw[->,thick] (3,-5.5) --  ++(0,3) -- ++(12,0) -- ++(0,5);
     %\pause
     \draw[->,thick] (18.5,5) --  +(3,0);
     %\pause
     \foreach \x in {5,...,1}
       \draw[fill=blue,xshift=600pt] (\x,\x) rectangle +(4,4);
     \node[fill=black!10, text width= 2.8cm] (GeoRefSeries) at
       (28,-1) {Geo-referenced Series};
%\pause
      

       \draw[->,thick] (25.5,8.5) --  +(0,3);
       
     \draw[fill=black!30,rounded corners=2pt] (22,12) rectangle +(8.5,4);
     \node[text width= 1.5cm] (HomPoExtr) at (27,14) {Homologous Points};

     \draw[->,thick] (21.5,14) --  +(-2.5,0);

     \draw[fill=black!30,rounded corners=2pt] (11,12) rectangle +(8,4);
     \node[text width= 1.3cm] (BBAdj) at (15.5,14) {Bundle-block Adjustement};

     \draw[->,thick] (15,11.5) --  +(0,-4);

     %\pause
      \draw[->,thick] (30,5) --  +(3,0);
      %\pause
     \draw[fill=black!30,rounded corners=2pt] (33.2,2.5) rectangle +(6,4.5);
     \node[text width= 0.7cm] (FineRegistration) at (36,4.9) {Fine Registration};
     %\pause

     
     \draw[->,thick] (39.5,5) --  +(3,0);
     %\pause
     \foreach \x in {5,...,1}
       \draw[fill=green,xshift=1200pt] (\x,\x) rectangle +(4,4);
     \node[fill=black!10, text width= 1.8cm] (RegistSeries) at
       (47,-1) {Registered Series};
     %\pause
     \draw[->,thick] (36,2) --  ++(0,-10) -- ++(-30,0);

     %\pause
      \draw[->,thick] (52,5) --  +(3,0);
      %\pause
     \draw[fill=black!30,rounded corners=2pt] (55.2,2.5) rectangle +(6,4.5);
     \node[text width= 0.7cm] (CartoProjection) at (57.5,4.9)
          {Map Projection};
     %\pause

     
     \draw[->,thick] (61.5,5) --  +(3,0);
     %\pause
     \foreach \x in {5,...,1}
       \draw[fill=yellow,xshift=1810pt] (\x,\x) rectangle +(4,4);
     \node[fill=black!10, text width= 1.95cm] (CartoSeries) at
       (68,-1) {Cartographic Series};
     
       
     \end{tikzpicture}
     \end{center}
     #+END_LaTeX

     These steps can vary depending on the sensor and the product levels.

     In the exercise we will only perform image orthorectification of the
     pan-sharpened product to discover the modes available in OTB.
     
     Use  the *Orthorectification* application to perform the
     orthorectification:

        1. Without Digital Elevation Model (DEM)
        2. With a DEM and a geoid (use the ~SRTM~ directory)
        3. Compare the 2 images in Monteverdi. What do you notice?
        4. What is the projection system by default in the *Orthorectification* application?
        5. In which UTM zone is located the Pleiades image?
        6. Test different projection systems (WGS84, Lambert 93) and open the ortho image in QGIS.

** Pre-processing of VHR satellite images                 :solutions:
*** Atmospheric corrections
     
    Compute TOA reflectance:

    #+BEGIN_EXAMPLE
    $ otbcli_OpticalCalibration \
    -in phr_xs_osr_mipy.tif \
    -out phr_xs_osr_mipy_toa.tif uint16 \
    -level toa \
    -milli 1
    #+END_EXAMPLE

    #+BEGIN_EXAMPLE
    $ otbcli_OpticalCalibration \
    -in phr_pan_osr_mipy.tif \
    -out phr_pan_osr_mipy_toa.tif uint16 \
    -level toa \
    -milli 1
    #+END_EXAMPLE


    Compute TOC reflectance:

     #+BEGIN_EXAMPLE
    $ otbcli_OpticalCalibration 
    -in phr_xs_osr_mipy.tif \
    -out phr_xs_osr_mipy_toc.tif uint16 \
    -level toc \
    -milli 1
    #+END_EXAMPLE

    #+BEGIN_EXAMPLE
    $ otbcli_OpticalCalibration 
    -in phr_pan_osr_mipy.tif \
    -out phr_pan_osr_mipy_toc.tif uint16 \
    -level toc \
    -milli 1
    #+END_EXAMPLE

    We can use the *BandMathX* application to compute image differences:

    #+BEGIN_EXAMPLE
    $ otbcli_BandMathX 
    -il phr_xs_osr_mipy_toa.tif phr_xs_osr_mipy_toc.tif \
    -out diff_xs_toa_toc.tif int16 \
    -exp "im1-im2"
    #+END_EXAMPLE

    Then, for the panchromatic image:

    #+BEGIN_EXAMPLE
    $ otbcli_BandMath 
    -il phr_pan_osr_mipy_toa.tif phr_pan_osr_mipy_toc.tif \
    -out diff_pan_toa_toc.tif int16 \
    -exp "im1b1-im2b1"
    #+END_EXAMPLE

    The blue band is more impacted by atmospheric effects. Indeed molecular
    diffusion on the signal is high in this spectral range ($\lambda^{-4}$ decay). 

*** P+XS Fusion
    #+BEGIN_EXAMPLE
    $ otbcli_BundleToPerfectSensor \
    -inp phr_pan_osr_mipy_toa.tif \
    -inxs phr_xs_osr_mipy_toa.tif \
    -mode phr \
    -out phr_pxs_osr_mipy.tif uint16
    #+END_EXAMPLE
*** Ortho-rectification

    1. Orthorectification without DEM:
       #+BEGIN_EXAMPLE
       $ otbcli_OrthoRectification \
       -io.in phr_pxs_osr_mipy.tif \
       -io.out phr_orthopxs_osr_mipy.tif uint16
       #+END_EXAMPLE
    2. Orthorectification with DEM and geoid:
       #+BEGIN_EXAMPLE
       $ otbcli_OrthoRectification \
       -io.in phr_pxs_osr_mipy.tif \
       -io.out phr_orthopxs_osr_mipy.tif uint16 \ 
       -elev.dem SRTM/ \
       -elev.geoid Geoid/egm96.grd
       #+END_EXAMPLE
    3. Default projection is UTM. In our case the UTM zone is 32 North. 
    4. Orthorectification in WGS84 and in Lambert 93:
       #+BEGIN_EXAMPLE
       $ otbcli_OrthoRectification \
       -io.in phr_pxs_osr_mipy.tif \
       -io.out phr_orthopxs_osr_mipy.tif uint16 \ 
       -elev.dem SRTM/ \
       -elev.geoid Geoid/egm96.grd \ 
       -map epsg -map.epsg.code 4326
       #+END_EXAMPLE

       #+BEGIN_EXAMPLE
       $ otbcli_OrthoRectification \
       -io.in phr_pxs_osr_mipy.tif \
       -io.out phr_orthopxs_osr_mipy.tif uint16 \
       -elev.dem SRTM/ \
       -elev.geoid Geoid/egm96.grd \
       -map lambert93
       #+END_EXAMPLE
